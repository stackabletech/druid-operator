= Stackable Operator for Apache Druid
:description: The Stackable Operator for Apache Druid is a Kubernetes operator that can manage Apache Druid clusters. Learn about its features, resources, dependencies, and demos, and see the list of supported Druid versions.
:keywords: Stackable Operator, Apache Druid, Kubernetes, operator, DevOps, engineer, CRD, StatefulSet, ConfigMap, Service, ZooKeeper, HDFS, S3, Kafka, Trino, OPA, demo, version

The Stackable Operator for Apache Druid is an operator that can deploy and manage https://druid.apache.org/[Apache Druid] clusters on Kubernetes. This operator provides several resources and features to manage Druid clusters efficiently.

== Getting Started

To get started with the Stackable Operator for Apache Druid, follow the xref:druid:getting_started/index.adoc[Getting Started guide]. The Operator is installed along with the _DruidCluster_ CustomResourceDefinition, which supports five xref:home:concepts:roles-and-role-groups.adoc[roles]: **Router**, **Coordinator**, **Broker**, **MiddleManager** and **Historical**. These roles correspond to https://druid.apache.org/docs/latest/design/processes.html[Druid processes].

== Resources

The Operator watches DruidCluster objects and creates multiple Kubernetes resources for each DruidCluster based on its configuration.

image::druid_overview.drawio.svg[A diagram depicting the Kubernetes resources the operator creates]

For every RoleGroup a **StatefulSet** is created. Each StatefulSet can contain multiple replicas (Pods). each Pod has at least two containers: the main Druid container and a preparation container which just runs once at startup. If xref:usage-guide/logging.adoc[] is enabled, there is a sidecar container for logging too.
For every Role and RoleGroup the Operator creates a **Service**.

A **ConfigMap** is created for each RoleGroup containing 3 files. A generated `jvm.config` and `runtime.properties` file based on the DruidCluster configuration (See xref:usage-guide/index.adoc[] for more information). A `log4j2.properties` file used for xref:usage-guide/logging.adoc[].
For the whole DruidCluster a **xref:discovery.adoc[discovery ConfigMap]** is created which contains information on how to connect to the Druid cluster.

== Dependencies and other Operators to connect to

The Druid Operator has the following dependencies:

* A xref:usage-guide/deep-storage.adoc[deep storage] backend is required to persist data. Use either xref:usage-guide/deep-storage.adoc#hdfs[HDFS] with the xref:hdfs:index.adoc[] or xref:usage-guide/deep-storage.adoc#s3[S3].
* An SQL database to store metadata.
* Apache ZooKeeper via the xref:zookeeper:index.adoc[]. Apache ZooKeeper is used by Druid for internal communication between processes.
* The xref:commons-operator:index.adoc[] provides common CRDs such as xref:concepts:s3.adoc[] CRDs.
* The xref:secret-operator:index.adoc[] is required for things like S3 access credentials or LDAP integration.

Have a look at the xref:getting_started/index.adoc[getting started guide] for an example of a minimal working setup. Druid can work well with other Stackable supported products, xref:kafka:index.adoc[Apache Kafka] for data ingestion xref:trino:index.adoc[Trino] for data processing orxref:superset:index.adoc[Superset] for data visualization. xref:opa:index.adoc[OPA] can be connected to create authorization policies. Have a look at the xref:usage-guide/index.adoc[] for more configuration options and have a look at the <<demos, demos>> for complete data pipelines you can install with a single command.

== [[demos]]Demos

xref:stackablectl::index.adoc[] supports installing xref:stackablectl::demos/index.adoc[] with a single command. The demos are complete data piplines which showcase multiple components of the Stackable platform working together and for you to try out interactively. Both demos below include Druid as part of the data pipeline:

=== Waterlevel Demo

The xref:stackablectl::demos/nifi-kafka-druid-water-level-data.adoc[] demo uses data from https://www.pegelonline.wsv.de/webservice/ueberblick[PEGELONLINE] to visualize water levels in rivers and coastal regions of Germany from historic and real time data.

=== Earthquake Demo

The xref:stackablectl::demos/nifi-kafka-druid-earthquake-data.adoc[] demo ingests https://earthquake.usgs.gov/[earthquake data] into a similar pipeline as is used in the waterlevel demo.


== Supported Versions

The Stackable Operator for Apache Druid currently supports the following versions of Druid:

include::partial$supported-versions.adoc[]
