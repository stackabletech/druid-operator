= Stackable Operator for Apache Druid

This is an operator for Kubernetes that can manage https://druid.apache.org/[Apache Druid] clusters. Dive right in with the xref:druid:getting_started/index.adoc[Getting Started guide].

Installing the Operator also installs the _DruidCluster_ CustomResourceDefinition. The DruidCluster definition supports 5 xref:home:concepts:roles-and-role-groups.adoc[roles]: **Router**, **Coordinator**, **Broker**, **MiddleManager** and **Historical**.
The roles correspond to https://druid.apache.org/docs/latest/design/processes.html[Druid processes].

== Resources

The Operator watches DruidCluster objects and creates multiple Kubernetes resources for each DruidCluster based its configuration.

image::druid_overview.drawio.svg[A diagram depicting the Kubernetes resources the operator creates]

For every RoleGroup a **StatefulSet** is created. Each StatefulSet can contain multiple replicas (Pods). In each Pod are two containers: the main Druid container and a preparation container (TODO what for exactly?).

A **ConfigMap** is created for each RoleGroup containing 3 files. A generated `jvm.config` and `runtime.properties` file based on ... (TODO). A `log4j2.properties` file used for xref:usage-guide/logging.adoc[].

For every Role and RoleGroup the Operator creates a **Service**.

For the whole DruidCluster a **xref:discovery.adoc[discovery ConfigMap]** is created which contains information on how to connect to the Druid cluster.

== Dependencies and Other Operators to connect to

The Druid Operator has the following dependencies:

* The xref:commons-operator:index.adoc[] provides common CRDs such as xref:concepts:s3.adoc[] CRDs.
* The xref:secret-operator:index.adoc[] is required for things like S3 access credentials or LDAP integration.
* Apache ZooKeeper via the xref:zookeeper:index.adoc[]. Apache ZooKeeper is used by Druid for internal communication between processes.
* A storage backend. Either HDFS with the xref:hdfs:index.adoc[] or S3. (TODO: link to S3 deep storage config usage).
* An SQL database to store metadata.

You can ingest data from Kafka with the xref:kafka:index.adoc[].

Trino with the xref:trino:index.adoc[] can read from Druid.

OPA with the xref:opa:index.adoc[] for Authorization.

== Demos

xref:stackablectl::index.adoc[] supports installing xref:stackablectl::demos/index.adoc[] which showcase multiple components of the Stackable platform working together. These two demos include Druid as part of the data pipeline:

=== Waterlevel Demo

The xref:stackablectl::demos/nifi-kafka-druid-water-level-data.adoc[] demo uses data from https://www.pegelonline.wsv.de/webservice/ueberblick[PEGELONLINE] to visualize water levels in rivers and coastal regions of Germany from historic and real time data.

=== Earthquake Demo

The xref:stackablectl::demos/nifi-kafka-druid-earthquake-data.adoc[] demo ...


== Supported Versions

The Stackable Operator for Apache Druid currently supports the following versions of Druid:

include::partial$supported-versions.adoc[]
